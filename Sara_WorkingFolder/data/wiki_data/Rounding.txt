rounding a numerical value means replacing it by another value that is approximately equal but has a shorter simpler or more explicit representation; for example replacing 23.4476 with 23.45 or the fraction 312/937 with 1/3 or the expression 2 with 1.414
rounding is often done to obtain a value that is easier to report and communicate than the original rounding can also be important to avoid misleadingly precise reporting of a computed number measurement or estimate; for example a quantity that was computed as 123,456 but is known to be accurate only to within a few hundred units is better stated as "about 123,500"
on the other hand rounding of exact numbers will introduce some round-off error in the reported result rounding is almost unavoidable when reporting many computations especially when dividing two numbers in integer or fixed-point arithmetic; when computing mathematical functions such as square roots logarithms and sines; or when using a floating point representation with a fixed number of significant digits in a sequence of calculations these rounding errors generally accumulate and in certain ill-conditioned cases they may make the result meaningless
accurate rounding of transcendental mathematical functions is difficult because the number of extra digits that need to be calculated to resolve whether to round up or down cannot be known in advance this problem is known as "the table-maker's dilemma"
rounding has many similarities to the quantization that occurs when physical quantities must be encoded by numbers or digital signals
a wavy equals sign () is sometimes used to indicate rounding of exact numbers for example: 9.98 10
== types of rounding ==
typical rounding problems are:
approximating an irrational number by a fraction e.g. by 22/7;
approximating a fraction with periodic decimal expansion by a finite decimal fraction e.g. 5/3 by 1.6667;
replacing a rational number by a fraction with smaller numerator and denominator e.g. 3122/9417 by 1/3;
replacing a fractional decimal number by one with fewer digits e.g. 2.1784 dollars by 2.18 dollars;
replacing a decimal integer by an integer with more trailing zeros e.g. 23,217 people by 23,200 people; or in general
replacing a value by a multiple of a specified amount e.g. 48.2 seconds by 45 seconds (a multiple of 15 s)
== rounding to a specified increment ==
the most common type of rounding is to round to an integer; or more generally to an integer multiple of some increment such as rounding to whole tenths of seconds hundredths of a dollar to whole multiples of 1/2 or 1/8 inch to whole dozens or thousands etc
in general rounding a number x to a multiple of some specified increment m entails the following steps:
divide x by m let the result be y;
round y to an integer value call it q;
multiply q by m to obtain the rounded value z
for example rounding x = 2.1784 dollars to whole cents (i.e. to a multiple of 0.01) entails computing y = x/m = 2.1784/0.01 = 217.84 then rounding y to the integer q = 218 and finally computing z = qm = 2180.01 = 2.18
when rounding to a predetermined number of significant digits the increment m depends on the magnitude of the number to be rounded (or of the rounded result)
the increment m is normally a finite fraction in whatever number system is used to represent the numbers for display to humans that usually means the decimal number system (that is m is an integer times a power of 10 like 1/1000 or 25/100) for intermediate values stored in digital computers it often means the binary number system (m is an integer times a power of 2)
the abstract single-argument "round()" function that returns an integer from an arbitrary real value has at least a dozen distinct concrete definitions presented in the rounding to integer section the abstract two-argument "round()" function is formally defined here but in many cases it is used with the implicit value m = 1 for the increment and then reduces to the equivalent abstract single-argument function with also the same dozen distinct concrete definitions
== rounding to integer ==
the most basic form of rounding is to replace an arbitrary number by an integer all the following rounding modes are concrete implementations of the abstract single-argument "round()" function presented and used in the previous sections
there are many ways of rounding a number y to an integer q the most common ones are
round down (or take the floor or round towards minus infinity): q is the largest integer that does not exceed y
round up (or take the ceiling or round towards plus infinity): q is the smallest integer that is not less than y
round towards zero (or truncate or round away from infinity): q is the integer part of y without its fraction digits
round away from zero (or round towards infinity): if y is an integer q is y; else q is the integer that is closest to 0 and is such that y is between 0 and q
round to nearest: q is the integer that is closest to y (see below for tie-breaking rules)
the first four methods are called directed rounding as the displacements from the original number y to the rounded value q are all directed towards or away from the same limiting value (0 + or )
if y is positive round-down is the same as round-towards-zero and round-up is the same as round-away-from-zero if y is negative round-down is the same as round-away-from-zero and round-up is the same as round-towards-zero in any case if y is integer q is just y
where many calculations are done in sequence the choice of rounding method can have a very significant effect on the result a famous instance involved a new index set up by the vancouver stock exchange in 1982 it was initially set at 1000.000 (three decimal places of accuracy) and after 22 months had fallen to about 520 whereas stock prices had generally increased in the period the problem was caused by the index being recalculated thousands of times daily and always being rounded down to 3 decimal places in such a way that the rounding errors accumulated recalculating with better rounding gave an index value of 1098.892 at the end of the same period
=== tie-breaking ===
rounding a number y to the nearest integer requires some tie-breaking rule for those cases when y is exactly half-way between two integers that is when the fraction part of y is exactly 0.5
==== round half up ====
the following tie-breaking rule called round half up (or round half towards positive infinity) is widely used in many disciplines that is half-way values y are always rounded up
if the fraction of y is exactly 0.5 then q = y + 0.5
for example by this rule the value 23.5 gets rounded to 24 but 23.5 gets rounded to 23
however some programming languages (such as java) define half_up as round half away from zero
if it were not for the 0.5 fractions the round-off errors introduced by the round to nearest method would be symmetric: for every fraction that gets rounded up (such as 0.268) there is a complementary fraction (namely 0.732) that gets rounded down by the same amount when rounding a large set of numbers with random fractional parts these rounding errors would statistically compensate each other and the expected (average) value of the rounded numbers would be equal to the expected value of the original numbers
however the round half up tie-breaking rule is not symmetric as the fractions that are exactly 0.5 always get rounded up this asymmetry introduces a positive bias in the round-off errors for example if the fraction of y consists of three random decimal digits then the expected value of q will be 0.0005 higher than the expected value of y for this reason round-to-nearest with the round half up rule is also (ambiguously) known as asymmetric rounding
one reason for rounding up at 0.5 is that for positive decimals only the first figure after the decimal point needs be examined for example when looking at 17.5000 the "5" alone determines that the number should be rounded up to 18 in this case this is not true for negative decimals such as 17.5000 where all the fractional figures of the value need to be examined to determine if it should round to 17 (if it were 17.5000000) or to 18 (if it were 17.5000001 or lower)
==== round half down ====
one may also use round half down (or round half towards negative infinity) as opposed to the more common round half up
if the fraction of y is exactly 0.5 then q = y 0.5
for example 23.5 gets rounded to 23 and 23.5 gets rounded to 24
the round half down tie-breaking rule is not symmetric as the fractions that are exactly 0.5 always get rounded down this asymmetry introduces a negative bias in the roundoff errors for example if the fraction of y consists of three random decimal digits then the expected value of q will be 0.0005 lower than the expected value of y for this reason round-to-nearest with the round half down rule is also (ambiguously) known as asymmetric rounding
==== round half towards zero ====
one may also round half towards zero (or round half away from infinity) as opposed to the conventional round half away from zero
if the fraction of y is exactly 0.5 then q = y 0.5 if y is positive and q = y + 0.5 if y is negative
for example 23.5 gets rounded to 23 and 23.5 gets rounded to 23
this method also treats positive and negative values symmetrically and therefore is free of overall bias if the original numbers are positive or negative with equal probability
==== round half away from zero ====
the other tie-breaking method commonly taught and used is the round half away from zero (or round half towards infinity) namely:
if the fraction of y is exactly 0.5 then q = y + 0.5 if y is positive and q = y 0.5 if y is negative
for example 23.5 gets rounded to 24 and 23.5 gets rounded to 24
this method treats positive and negative values symmetrically and therefore is free of overall bias if the original numbers are positive or negative with equal probability
it is often used for currency conversions and price roundings (when the amount is first converted into the smallest significant subdivision of the currency such as cents of a euro) as it is easy to explain by just considering the first fractional digit independently of supplementary precision digits or sign of the amount (for strict equivalence between the paying and recipient of the amount)
==== round half to even ====
a tie-breaking rule that is less biased is round half to even namely:
if the fraction of y is 0.5 then q is the even integer nearest to y
thus for example +23.5 becomes +24 as does +24.5; while 23.5 becomes 24 as does 24.5
this method treats positive and negative values symmetrically and is therefore free of sign bias more importantly for reasonable distributions of y values the expected (average) value of the rounded numbers is the same as that of the original numbers however this rule will introduce a towards-zero bias when y 0.5 is even and a towards-infinity bias for when it is odd
this variant of the round-to-nearest method is also called unbiased rounding convergent rounding statistician's rounding dutch rounding gaussian rounding oddeven rounding or bankers' rounding
this is the default rounding mode used in ieee 754 computing functions and operators
==== round half to odd ====
a similar tie-breaking rule is round half to odd:
if the fraction of y is 0.5 then q is the odd integer nearest to y
thus for example +23.5 becomes +23 as does +22.5; while 23.5 becomes 23 as does 22.5
this method also treats positive and negative values symmetrically and is therefore free of sign bias more importantly for reasonable distributions of y values the expected (average) value of the rounded numbers is the same as that of the original numbers however this rule will introduce a towards-zero bias when y 0.5 is odd and a towards-infinity bias for when it is even
this variant is almost never used in computations except in situations where one wants to avoid rounding 0.5 or 0.5 to zero; or to avoid increasing the scale of floating point numbers which have a limited exponent range with round half to even a non infinite number would round to infinity and a small denormal value would round to a normal non-zero value effectively this mode prefers preserving the existing scale of tie numbers avoiding out of range results when possible for even based number systems (such as binary and decimal)
=== stochastic rounding ===
another unbiased tie-breaking method is stochastic rounding:
if the fractional part of y is 0.5 choose q randomly among y + 0.5 and y 0.5 with equal probability
like round-half-to-even this rule is essentially free of overall bias; but it is also fair among even and odd q values on the other hand it introduces a random component into the result; performing the same computation twice on the same data may yield two different results also it is open to nonconscious bias if humans (rather than computers or devices of chance) are "randomly" deciding in which direction to round
=== alternating tie-breaking ===
one method more obscure than most is round half alternatingly
if the fractional part is 0.5 alternate round up and round down: for the first occurrence of a 0.5 fractional part round up; for the second occurrence round down; so on so forth
this suppresses the random component of the result if occurrences of 0.5 fractional parts can be effectively numbered but it can still introduce a positive or negative bias according to the direction of rounding assigned to the first occurrence if the total number of occurrences is odd
== dithering and error diffusion ==
when digitising continuous signals for example images or sound the overall effect of a number of measurements is more important than the accuracy of each individual measurement in these circumstances dithering and a related technique error diffusion are normally used a related technique called pulse-width modulation is used to achieve analogue type output from an inertial device by rapidly pulsing the power with a variable duty cycle
error diffusion tries to ensure the error on average is minimized when dealing with a gentle slope from one to zero the output would be zero for the first few terms until the sum of the error and the current value becomes greater than 0.5 in which case a 1 is output and the difference subtracted from the error so far floydsteinberg dithering is a popular error diffusion procedure when digitising images
== rounding to simple fractions ==
in some contexts it is desirable to round a given number x to a "neat" fraction that is the nearest fraction z = m/n whose numerator m and denominator n do not exceed a given maximum this problem is fairly distinct from that of rounding a value to a fixed number of decimal or binary digits or to a multiple of a given unit m this problem is related to farey sequences the sternbrocot tree and continued fractions
== scaled rounding ==
this type of rounding which is also named rounding to a logarithmic scale is a variant of rounding to a specified increment rounding on a logarithmic scale is accomplished by taking the log of the amount and doing normal rounding to the nearest value on the log scale
for example resistors are supplied with preferred numbers on a logarithmic scale for example for resistors with 10% accuracy they are supplied with nominal values 100 121 147 178 215 etc if a calculation indicates a resistor of 165 ohms is required then log(147)=2.167 log(165)=2.217 and log(178)=2.250 the logarithm of 165 is closer to the logarithm of 178 therefore a 178 ohm resistor would be the first choice if there are no other considerations
== round to available value ==
finished lumber writing paper capacitors and many other products are usually sold in only a few standard sizes
many design procedures describe how to calculate an approximate value and then "round" to some standard size using phrases such as "round down to nearest standard value" "round up to nearest standard value" or "round to nearest standard value"
when a set of preferred values is equally spaced on a logarithmic scale choosing the closest preferred value to any given value can be seen as a kind of scaled rounding such "rounded" values can be directly calculated
== floating-point rounding ==
in floating-point arithmetic rounding aims to turn a given value x into a value z with a specified number of significant digits in other words z should be a multiple of a number m that depends on the magnitude of x the number m is a power of the base (usually 2 or 10) of the floating-point representation
apart from this detail all the variants of rounding discussed above apply to the rounding of floating-point numbers as well the algorithm for such rounding is presented in the scaled rounding section above but with a constant scaling factor s = 1 and an integer base b > 1
for results where the rounded result would overflow the result for a directed rounding is either the appropriate signed infinity or the highest representable positive finite number (or the lowest representable negative finite number if x is negative) depending on the direction of rounding the result of an overflow for the usual case of round to nearest is always the appropriate infinity
== double rounding ==
rounding a number twice in succession to different precisions with the latter precision being coarser is not guaranteed to give the same result as rounding once to the final precision except in the case of directed rounding for instance rounding 9.46 to one decimal gives 9.5 and then 10 when rounding to integer using rounding half to even but would give 9 when rounded to integer directly borman and chatfield discuss the implications of double rounding when comparing data rounded to one decimal place to specification limits expressed using integers
in martinez v allstate and sendejo v farmers litigated between 1995 and 1997 the insurance companies argued that double rounding premiums was permissible and in fact required the us courts ruled against the insurance companies and ordered them to adopt rules to ensure single rounding
some computer languages and the ieee 754-2008 standard dictate that in straightforward calculations the result should not be rounded twice this has been a particular problem with java as it is designed to be run identically on different machines special programming tricks have had to be used to achieve this with x87 floating point the java language was changed to allow different results where the difference does not matter and require a strictfp qualifier to be used when the results have to conform accurately
== exact computation with rounded arithmetic ==
it is possible to use rounded arithmetic to evaluate the exact value of a function with a discrete domain and range for example if we know that an integer n is a perfect square we can compute its square root by converting n to a floating-point value x computing the approximate square root y of x with floating point and then rounding y to the nearest integer q if n is not too big the floating-point roundoff error in y will be less than 0.5 so the rounded value q will be the exact square root of n in most modern computers this method may be much faster than computing the square root of n by an all-integer algorithm
== table-maker's dilemma ==
william kahan coined the term "the table-maker's dilemma" for the unknown cost of rounding transcendental functions:
"nobody knows how much it would cost to compute yw correctly rounded for every two floating-point arguments at which it does not over/underflow instead reputable math libraries compute elementary transcendental functions mostly within slightly more than half an ulp and almost always well within one ulp why can't yw be rounded within half an ulp like sqrt because nobody knows how much computation it would cost no general way exists to predict how many extra digits will have to be carried to compute a transcendental expression and round it correctly to some preassigned number of digits even the fact (if true) that a finite number of extra digits will ultimately suffice may be a deep theorem."
the ieee floating point standard guarantees that add subtract multiply divide fused multiplyadd square root and floating point remainder will give the correctly rounded result of the infinite precision operation no such guarantee was given in the 1985 standard for more complex functions and they are typically only accurate to within the last bit at best however the 2008 standard guarantees that conforming implementations will give correctly rounded results which respect the active rounding mode; implementation of the functions however is optional
using the gelfondschneider theorem and lindemannweierstrass theorem many of the standard elementary functions can be proved to return transcendental results when given rational non-zero arguments; therefore it is always possible to correctly round such functions however determining a limit for a given precision on how accurate results need to be computed before a correctly rounded result can be guaranteed may demand a lot of computation time
some packages offer correct rounding the gnu mpfr package gives correctly rounded arbitrary precision results some other libraries implement elementary functions with correct rounding in double precision:
ibm's libultim in rounding to nearest only
sun microsystems's libmcr in the 4 rounding modes
crlibm written in the arnaire team (lip ens lyon) it supports the 4 rounding modes and is proved
there exist computable numbers for which a rounded value can never be determined no matter how many digits are calculated specific instances cannot be given but this follows from the undecidability of the halting problem for instance if goldbach's conjecture is true but unprovable then the result of rounding the following value up to the next integer cannot be determined: 10n where n is the first even number greater than 4 which is not the sum of two primes or 0 if there is no such number the result is 1 if such a number exists and 0 if no such number exists the value before rounding can however be approximated to any given precision even if the conjecture is unprovable
== history ==
the concept of rounding is very old perhaps older even than the concept of division some ancient clay tablets found in mesopotamia contain tables with rounded values of reciprocals and square roots in base 60 rounded approximations to  the length of the year and the length of the month are also ancientsee base 60#examples
the round-to-even method has served as the astm (e-29) standard since 1940 the origin of the terms unbiased rounding and statistician's rounding are fairly self-explanatory in the 1906 4th edition of probability and theory of errors robert simpson woodward called this "the computer's rule" indicating that it was then in common use by human computers who calculated mathematical tables churchill eisenhart indicated the practice was already "well established" in data analysis by the 1940s
the origin of the term bankers' rounding remains more obscure if this rounding method was ever a standard in banking the evidence has proved extremely difficult to find to the contrary section 2 of the european commission report the introduction of the euro and the rounding of currency amounts suggests that there had previously been no standard approach to rounding in banking; and it specifies that "half-way" amounts should be rounded up
until the 1980s the rounding method used in floating-point computer arithmetic was usually fixed by the hardware poorly documented inconsistent and different for each brand and model of computer this situation changed after the ieee 754 floating point standard was adopted by most computer manufacturers the standard allows the user to choose among several rounding modes and in each case specifies precisely how the results should be rounded these features made numerical computations more predictable and machine-independent and made possible the efficient and consistent implementation of interval arithmetic
== rounding functions in programming languages ==
most programming languages provide functions or special syntax to round fractional numbers in various ways the earliest numeric languages such as fortran and c would provide only one method usually truncation (towards zero) this default method could be implied in certain contexts such as when assigning a fractional number to an integer variable or using a fractional number as an index of an array other kinds of rounding had to be programmed explicitly; for example rounding a positive number to the nearest integer could be implemented by adding 0.5 and truncating
in the last decades however the syntax and/or the standard libraries of most languages have commonly provided at least the four basic rounding functions (up down to nearest and towards zero) the tie-breaking method may vary depending the language and version and/or may be selectable by the programmer several languages follow the lead of the ieee-754 floating-point standard and define these functions as taking a double precision float argument and returning the result of the same type which then may be converted to an integer if necessary this approach may avoid spurious overflows since floating-point types have a larger range than integer types some languages such as php provide functions that round a value to a specified number of decimal digits e.g from 4321.5678 to 4321.57 or 4300 in addition many languages provide a printf or similar string formatting function which allows one to convert a fractional number to a string rounded to a user-specified number of decimal places (the precision) on the other hand truncation (round to zero) is still the default rounding method used by many languages especially for the division of two integer values
on the opposite css and svg do not define any specific maximum precision for numbers and measurements that are treated and exposed in their dom and in their idl interface as strings as if they had infinite precision and do not discriminate between integers and floating point values; however the implementations of these languages will typically convert these numbers into ieee-754 double floating points before exposing the computed digits with a limited precision (notably within standard javascript or ecmascript interface bindings)
== other rounding standards ==
some disciplines or institutions have issued standards or directives for rounding
=== u.s weather observations ===
in a guideline issued in mid-1966 the u.s office of the federal coordinator for meteorology determined that weather data should be rounded to the nearest round number with the "round half up" tie-breaking rule for example 1.5 rounded to integer should become 2 and 1.5 should become 1 prior to that date the tie-breaking rule was "round half away from zero"
=== negative zero in meteorology ===
some meteorologists may write "0" to indicate a temperature between 0.0 and 0.5 degrees (exclusive) that was rounded to integer this notation is used when the negative sign is considered important no matter how small is the magnitude; for example when rounding temperatures in the celsius scale where below zero indicates freezing
== see also ==
gal's accurate tables
interval arithmetic
iso 80000-1:2009
kahan summation algorithm
nearest integer function
truncation
signed-digit representation
swedish rounding to avoid the use of coins of extremely low value
== references ==
== external links ==
weisstein eric w. "rounding" mathworld
an introduction to different rounding algorithms that is accessible to a general audience but especially useful to those studying computer science and electronics
how to implement custom rounding procedures by microsoft
